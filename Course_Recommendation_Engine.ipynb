{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec9b696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (4.60.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (10.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence_transformers) (4.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2021.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2021.10.8)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\saura\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saura\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\saura\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Profile: I’ve completed the ‘Python Programming for Data Science’ course and enjoy data visualization.\n",
      " Completed: ['DS101']\n",
      "\n",
      " Top-5 Course Recommendations:\n",
      "- Python Programming for Data Science (ID: C016, Score: 0.6652)\n",
      "- R Programming and Statistical Analysis (ID: C017, Score: 0.5432)\n",
      "- Data Visualization with Tableau (ID: C014, Score: 0.4931)\n",
      "- Foundations of Machine Learning (ID: C001, Score: 0.4729)\n",
      "- Big Data Analytics with Spark (ID: C011, Score: 0.4624)\n",
      " Profile: I know Azure basics and want to manage containers and build CI/CD pipelines.\n",
      " Completed: ['AZ101']\n",
      "\n",
      " Top-5 Course Recommendations:\n",
      "- Cloud Computing with Azure (ID: C007, Score: 0.568)\n",
      "- DevOps Practices and CI/CD (ID: C008, Score: 0.5403)\n",
      "- Containerization with Docker and Kubernetes (ID: C009, Score: 0.5311)\n",
      "- MLOps: Productionizing Machine Learning (ID: C025, Score: 0.4568)\n",
      "- Data Engineering on AWS (ID: C006, Score: 0.452)\n",
      " Profile: My background is in ML fundamentals; I’d like to specialize in neural networks and production workflows.\n",
      " Completed: ['ML201']\n",
      "\n",
      " Top-5 Course Recommendations:\n",
      "- MLOps: Productionizing Machine Learning (ID: C025, Score: 0.5365)\n",
      "- Deep Learning with TensorFlow and Keras (ID: C002, Score: 0.4922)\n",
      "- Foundations of Machine Learning (ID: C001, Score: 0.4654)\n",
      "- Reinforcement Learning Basics (ID: C005, Score: 0.4438)\n",
      "- Computer Vision and Image Processing (ID: C004, Score: 0.4384)\n",
      " Profile: I want to learn to build and deploy microservices with Kubernetes—what courses fit best?\n",
      " Completed: ['CN101']\n",
      "\n",
      " Top-5 Course Recommendations:\n",
      "- Containerization with Docker and Kubernetes (ID: C009, Score: 0.6471)\n",
      "- APIs and Microservices Architecture (ID: C010, Score: 0.5187)\n",
      "- Cloud Computing with Azure (ID: C007, Score: 0.489)\n",
      "- MLOps: Productionizing Machine Learning (ID: C025, Score: 0.465)\n",
      "- Deep Learning with TensorFlow and Keras (ID: C002, Score: 0.441)\n",
      " Profile: I’m interested in blockchain and smart contracts but have no prior experience.\n",
      " Completed: []\n",
      "\n",
      " Top-5 Course Recommendations:\n",
      "- Blockchain Technology and Smart Contracts (ID: C023, Score: 0.5881)\n",
      "- APIs and Microservices Architecture (ID: C010, Score: 0.4195)\n",
      "- NoSQL Databases and MongoDB (ID: C013, Score: 0.4167)\n",
      "- Internet of Things (IoT) Development (ID: C022, Score: 0.41)\n",
      "- Reinforcement Learning Basics (ID: C005, Score: 0.4072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas sentence-transformers faiss-cpu\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/Bluedata-Consulting/GAAPB02-training/refs/heads/main/Assignments/assignment2dataset.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df = df.dropna(subset=['course_id', 'title', 'description'])\n",
    "\n",
    "# Combine title + description for better context\n",
    "df[\"text\"] = df[\"title\"] + \". \" + df[\"description\"]\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute course embeddings\n",
    "course_embeddings = model.encode(df[\"text\"].tolist(), show_progress_bar=True)\n",
    "course_embeddings = np.array(course_embeddings).astype(\"float32\")\n",
    "\n",
    "# Index embeddings using FAISS\n",
    "dimension = course_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(course_embeddings)\n",
    "\n",
    "# Mapping from index to course_id\n",
    "id_mapping = df[\"course_id\"].tolist()\n",
    "\n",
    "# Recommendation function\n",
    "def recommend_courses(profile: str, completed_ids: List[str], top_k=5) -> List[Tuple[str, float]]:\n",
    "    query_embedding = model.encode([profile])[0].astype(\"float32\")\n",
    "    distances, indices = index.search(np.array([query_embedding]), top_k + len(completed_ids))\n",
    "    recommendations = []\n",
    "    for i, dist in zip(indices[0], distances[0]):\n",
    "        course_id = id_mapping[i]\n",
    "        if course_id not in completed_ids:\n",
    "            similarity = 1 / (1 + dist)\n",
    "            recommendations.append((course_id, round(similarity, 4)))\n",
    "        if len(recommendations) >= top_k:\n",
    "            break\n",
    "    return recommendations\n",
    "\n",
    "# Display helper\n",
    "def print_recommendations(profile: str, completed_ids: List[str]):\n",
    "    print(f\" Profile: {profile}\")\n",
    "    print(f\" Completed: {completed_ids}\")\n",
    "    results = recommend_courses(profile, completed_ids)\n",
    "    print(\"\\n Top-5 Course Recommendations:\")\n",
    "    for course_id, score in results:\n",
    "        course_info = df[df[\"course_id\"] == course_id].iloc[0]\n",
    "        print(f\"- {course_info['title']} (ID: {course_id}, Score: {score})\")\n",
    "\n",
    "# ----------------------------\n",
    "# Test Cases\n",
    "# ----------------------------\n",
    "\n",
    "test_profiles = [\n",
    "    {\n",
    "        \"profile\": \"I’ve completed the ‘Python Programming for Data Science’ course and enjoy data visualization.\",\n",
    "        \"completed\": [\"DS101\"]\n",
    "    },\n",
    "    {\n",
    "        \"profile\": \"I know Azure basics and want to manage containers and build CI/CD pipelines.\",\n",
    "        \"completed\": [\"AZ101\"]\n",
    "    },\n",
    "    {\n",
    "        \"profile\": \"My background is in ML fundamentals; I’d like to specialize in neural networks and production workflows.\",\n",
    "        \"completed\": [\"ML201\"]\n",
    "    },\n",
    "    {\n",
    "        \"profile\": \"I want to learn to build and deploy microservices with Kubernetes—what courses fit best?\",\n",
    "        \"completed\": [\"CN101\"]\n",
    "    },\n",
    "    {\n",
    "        \"profile\": \"I’m interested in blockchain and smart contracts but have no prior experience.\",\n",
    "        \"completed\": []\n",
    "    },\n",
    "]\n",
    "\n",
    "# Run all test cases\n",
    "for case in test_profiles:\n",
    "    print_recommendations(case[\"profile\"], case[\"completed\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
